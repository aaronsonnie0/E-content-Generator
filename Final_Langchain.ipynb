{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a4cc9368c8845699f2c280b84379be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".txt,.pdf,.docx",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_e92de49b9c794204bcf7fec13acc9d92",
            "metadata": [
              {
                "name": "Artificial Intelligence.txt",
                "type": "text/plain",
                "size": 6086,
                "lastModified": 1739034734179
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_eaf0a6e745a94a9fa42171951a281b6c"
          }
        },
        "e92de49b9c794204bcf7fec13acc9d92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf0a6e745a94a9fa42171951a281b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d2d1040d779d46cc94e32d2f52017a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a37dce884a6742e380c571a3f4908e8c",
              "IPY_MODEL_6c84533b7c9d4886a70880b08b3d17f0",
              "IPY_MODEL_bd5e18de42d6455cb2790ea1714fa8ea"
            ],
            "layout": "IPY_MODEL_5b529f4c24864e409a6a4d9328fe7744"
          }
        },
        "a37dce884a6742e380c571a3f4908e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Subject:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_73e5d2eaa9da44eeaa61a3fcf293467d",
            "placeholder": "Enter the subject",
            "style": "IPY_MODEL_42e6ebb804ea4c1f8d4063efaa888c03",
            "value": "Computer Science"
          }
        },
        "6c84533b7c9d4886a70880b08b3d17f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Easy",
              "Medium",
              "Hard"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Difficulty:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_f785f746eed14f60b559fb62d1663313",
            "style": "IPY_MODEL_d5a54ddba45a4b24a63ea81f1de0de88"
          }
        },
        "bd5e18de42d6455cb2790ea1714fa8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Generate Quiz",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_3a1e79e1c86b4a99b0086ada058fb663",
            "style": "IPY_MODEL_7fd13c01e792450f8baa14c6e03b67aa",
            "tooltip": ""
          }
        },
        "5b529f4c24864e409a6a4d9328fe7744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e5d2eaa9da44eeaa61a3fcf293467d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e6ebb804ea4c1f8d4063efaa888c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f785f746eed14f60b559fb62d1663313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a54ddba45a4b24a63ea81f1de0de88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a1e79e1c86b4a99b0086ada058fb663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fd13c01e792450f8baa14c6e03b67aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "871674c53f6c453d9dd2b2459ad5ee71": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_bac96d18182e415688f297d2fee833d2",
            "msg_id": "",
            "outputs": []
          }
        },
        "bac96d18182e415688f297d2fee833d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff2e320dfe24887a048dcad2dcee5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 0,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".txt,.pdf,.docx",
            "button_style": "",
            "data": [],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_617514676ec0468b8621712fc92a5151",
            "metadata": [],
            "multiple": false,
            "style": "IPY_MODEL_867e50b9906747ee85fd6b31c04d2de2"
          }
        },
        "617514676ec0468b8621712fc92a5151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "867e50b9906747ee85fd6b31c04d2de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "fa65b84d871d49a0a0fb5a1207fe3509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aadbb983a395473c9ba9c653e24b7b4a",
              "IPY_MODEL_7f209fd41b4b46beac932f4d981ab377",
              "IPY_MODEL_7bb3703264e241a681b3096eb08159c8"
            ],
            "layout": "IPY_MODEL_2579f9c8dcaa4f8f8cab9bd34695f773"
          }
        },
        "aadbb983a395473c9ba9c653e24b7b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Subject:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9ad77a86347e435eb54c9645353c2eb1",
            "placeholder": "Enter the subject",
            "style": "IPY_MODEL_904ff46d2f4944c69ea14f78d6249661",
            "value": ""
          }
        },
        "7f209fd41b4b46beac932f4d981ab377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Easy",
              "Medium",
              "Hard"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Difficulty:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_75029c3e235a42e0924aafc41f6de07c",
            "style": "IPY_MODEL_3f555564611443f2b1c3bf63754e7460"
          }
        },
        "7bb3703264e241a681b3096eb08159c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Generate Quiz",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_cd41f89c82e743bc909796427bda0e2c",
            "style": "IPY_MODEL_b7acceb23c0c4bf4878731fc994181c4",
            "tooltip": ""
          }
        },
        "2579f9c8dcaa4f8f8cab9bd34695f773": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ad77a86347e435eb54c9645353c2eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "904ff46d2f4944c69ea14f78d6249661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75029c3e235a42e0924aafc41f6de07c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f555564611443f2b1c3bf63754e7460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd41f89c82e743bc909796427bda0e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7acceb23c0c4bf4878731fc994181c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d5f2ffa9f88143d2900d67bc09d668f7": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_27c6d1f959ca4688a6c20323f9e2e42d",
            "msg_id": "",
            "outputs": []
          }
        },
        "27c6d1f959ca4688a6c20323f9e2e42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPi7kKASm3KM",
        "outputId": "bc92cc0a-ffdd-482e-c6bf-2bd5f8ac68df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain)\n",
            "  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.33\n",
            "    Uninstalling langchain-core-0.3.33:\n",
            "      Successfully uninstalled langchain-core-0.3.33\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.5\n",
            "    Uninstalling langchain-text-splitters-0.3.5:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.17\n",
            "    Uninstalling langchain-0.3.17:\n",
            "      Successfully uninstalled langchain-0.3.17\n",
            "Successfully installed langchain-0.3.18 langchain-core-0.3.34 langchain-text-splitters-0.3.6\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community\n",
            "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.34)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.5)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.17 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain google-generativeai\n",
        "!pip install -U langchain google-generativeai\n",
        "!pip install -q langchain-google-genai\n",
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Replace 'YOUR_GOOGLE_API_KEY' with your actual API key\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyC2_dKggLQ_4cdDqb8W047P6PzP0rcsUbI'"
      ],
      "metadata": {
        "id": "dmxq4ga9nCGH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "jXOtZcWknCsO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normal generation\n",
        "import google.generativeai as genai\n",
        "import textwrap\n",
        "\n",
        "# Configure API key (Replace with your actual API key)\n",
        "genai.configure(api_key=\"AIzaSyC2_dKggLQ_4cdDqb8W047P6PzP0rcsUbI\")\n",
        "\n",
        "# Function to generate a response from Gemini API\n",
        "def generate_response(prompt):\n",
        "    model = genai.GenerativeModel(\"gemini-pro\")\n",
        "    response = model.generate_content(prompt)\n",
        "    return \"\\n\".join(textwrap.fill(line, width=80) for line in response.text.split(\"\\n\"))\n",
        "\n",
        "# Generate 10 quiz questions on AI\n",
        "quiz_questions = generate_response(\"Generate 10 quiz questions on Artificial Intelligence.\")\n",
        "\n",
        "# Answer basic AI-related questions\n",
        "ai_definition = generate_response(\"What is AI?\")\n",
        "ml_definition = generate_response(\"What is Machine Learning?\")\n",
        "\n",
        "# Print the results\n",
        "print(\"\\n📌 10 AI Quiz Questions:\\n\", quiz_questions)\n",
        "print(\"\\n📌 What is AI?\\n\", ai_definition)\n",
        "print(\"\\n📌 What is Machine Learning?\\n\", ml_definition)\n"
      ],
      "metadata": {
        "id": "s9UgjGEpnwME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#General Interactive chatbot without 1,2,3\n",
        "import google.generativeai as genai\n",
        "import textwrap\n",
        "\n",
        "# Configure API key (Replace with your actual API key)\n",
        "genai.configure(api_key=\"AIzaSyC2_dKggLQ_4cdDqb8W047P6PzP0rcsUbI\")\n",
        "\n",
        "# Function to generate AI responses\n",
        "def chat_with_ai():\n",
        "    model = genai.GenerativeModel(\"gemini-pro\")\n",
        "\n",
        "    print(\"\\n🤖 AI Chatbot: Type 'exit' to end the conversation.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")  # Take user input\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"🤖 AI: Goodbye! Have a great day! 😊\")\n",
        "            break\n",
        "\n",
        "        response = model.generate_content(user_input)  # Generate AI response\n",
        "\n",
        "        # Format the output for better readability\n",
        "        formatted_response = \"\\n\".join(textwrap.fill(line, width=80) for line in response.text.split(\"\\n\"))\n",
        "\n",
        "        print(\"\\n🤖 AI:\", formatted_response, \"\\n\")\n",
        "\n",
        "# Start the chat\n",
        "chat_with_ai()"
      ],
      "metadata": {
        "id": "iSrlYIq6oG2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate content as 1,2,3 for quiz , summary, e materials without doc loaders\n",
        "# Install required libraries\n",
        "!pip install -q langchain langchain-google-genai google-generativeai\n",
        "\n",
        "# Import necessary modules\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Set your Google API key\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyC2_dKggLQ_4cdDqb8W047P6PzP0rcsUbI'\n",
        "\n",
        "# Initialize the Gemini model using LangChain\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "\n",
        "# Define prompt templates for different tasks\n",
        "quiz_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"level\"],\n",
        "    template=\"You are a helpful AI tutor. Generate 10 {level} level quiz questions for {subject}.\"\n",
        ")\n",
        "\n",
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"topic\"],\n",
        "    template=\"You are an expert in {subject}. Provide a concise summary of the topic: {topic}.\"\n",
        ")\n",
        "\n",
        "material_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"topic\"],\n",
        "    template=\"You are an expert in {subject}. Generate detailed e-learning material on the topic: {topic}.\"\n",
        ")\n",
        "\n",
        "# Create LLMChains for each task\n",
        "quiz_chain = LLMChain(llm=llm, prompt=quiz_prompt)\n",
        "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
        "material_chain = LLMChain(llm=llm, prompt=material_prompt)\n",
        "\n",
        "# Function to generate quiz questions\n",
        "def generate_quiz(subject, level=\"Easy\"):\n",
        "    return quiz_chain.run(subject=subject, level=level)\n",
        "\n",
        "# Function to generate summaries\n",
        "def generate_summary(subject, topic):\n",
        "    return summary_chain.run(subject=subject, topic=topic)\n",
        "\n",
        "# Function to generate e-learning materials\n",
        "def generate_material(subject, topic):\n",
        "    return material_chain.run(subject=subject, topic=topic)\n",
        "\n",
        "# Map numeric inputs to difficulty levels\n",
        "difficulty_map = {\n",
        "    \"1\": \"Easy\",\n",
        "    \"2\": \"Medium\",\n",
        "    \"3\": \"Hard\"\n",
        "}\n",
        "\n",
        "# Interactive chatbot loop\n",
        "def chatbot():\n",
        "    print(\"Welcome to the E-Learning Content Generator!\")\n",
        "    print(\"Choose an option:\")\n",
        "    print(\"1. Generate Quiz\")\n",
        "    print(\"2. Create Summary\")\n",
        "    print(\"3. Create E-Learning Materials\")\n",
        "    print(\"Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nEnter your choice (1/2/3): \").strip().lower()\n",
        "\n",
        "        if user_input == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        elif user_input == \"1\":  # Generate Quiz\n",
        "            subject = input(\"Enter the subject: \")\n",
        "            print(\"Choose difficulty level:\")\n",
        "            print(\"1. Easy\")\n",
        "            print(\"2. Medium\")\n",
        "            print(\"3. Hard\")\n",
        "            difficulty_choice = input(\"Enter difficulty level (1/2/3): \").strip()\n",
        "            level = difficulty_map.get(difficulty_choice, \"Easy\")  # Default to Easy if invalid input\n",
        "            print(\"\\nGenerating quiz...\\n\")\n",
        "            quiz = generate_quiz(subject, level)\n",
        "            print(quiz)\n",
        "\n",
        "        elif user_input == \"2\":  # Create Summary\n",
        "            subject = input(\"Enter the subject: \")\n",
        "            topic = input(\"Enter the topic: \")\n",
        "            print(\"\\nGenerating summary...\\n\")\n",
        "            summary = generate_summary(subject, topic)\n",
        "            print(summary)\n",
        "\n",
        "        elif user_input == \"3\":  # Create E-Learning Materials\n",
        "            subject = input(\"Enter the subject: \")\n",
        "            topic = input(\"Enter the topic: \")\n",
        "            print(\"\\nGenerating e-learning material...\\n\")\n",
        "            material = generate_material(subject, topic)\n",
        "            print(material)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# Run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "metadata": {
        "id": "kK23YgrxnY3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Langchain x Gemini, final with 1,2,3\n",
        "# Install required libraries\n",
        "!pip install -q langchain langchain-google-genai google-generativeai\n",
        "\n",
        "# Import necessary modules\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Set your Google API key\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyC2_dKggLQ_4cdDqb8W047P6PzP0rcsUbI'\n",
        "\n",
        "# Initialize the Gemini model using LangChain\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "\n",
        "# Define prompt templates for different tasks\n",
        "quiz_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"level\"],\n",
        "    template=\"You are a helpful AI tutor. Generate 10 {level} level quiz questions for {subject}.\"\n",
        ")\n",
        "\n",
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"topic\"],\n",
        "    template=\"You are an expert in {subject}. Provide a concise summary of the topic: {topic}.\"\n",
        ")\n",
        "\n",
        "material_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"topic\"],\n",
        "    template=\"You are an expert in {subject}. Generate detailed e-learning material on the topic: {topic}.\"\n",
        ")\n",
        "\n",
        "# Create LLMChains for each task\n",
        "quiz_chain = LLMChain(llm=llm, prompt=quiz_prompt)\n",
        "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
        "material_chain = LLMChain(llm=llm, prompt=material_prompt)\n",
        "\n",
        "# Function to generate quiz questions\n",
        "def generate_quiz(subject, level=\"Easy\"):\n",
        "    return quiz_chain.run(subject=subject, level=level)\n",
        "\n",
        "# Function to generate summaries\n",
        "def generate_summary(subject, topic):\n",
        "    return summary_chain.run(subject=subject, topic=topic)\n",
        "\n",
        "# Function to generate e-learning materials\n",
        "def generate_material(subject, topic):\n",
        "    return material_chain.run(subject=subject, topic=topic)\n",
        "\n",
        "# Map numeric inputs to difficulty levels\n",
        "difficulty_map = {\n",
        "    \"1\": \"Easy\",\n",
        "    \"2\": \"Medium\",\n",
        "    \"3\": \"Hard\"\n",
        "}\n",
        "\n",
        "# Interactive chatbot loop\n",
        "def chatbot():\n",
        "    print(\"Welcome to the E-Learning Content Generator!\")\n",
        "    print(\"Choose an option:\")\n",
        "    print(\"1. Generate Quiz\")\n",
        "    print(\"2. Create Summary\")\n",
        "    print(\"3. Create E-Learning Materials\")\n",
        "    print(\"Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nEnter your choice (1/2/3): \").strip().lower()\n",
        "\n",
        "        if user_input == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        elif user_input == \"1\":  # Generate Quiz\n",
        "            subject = input(\"Enter the subject: \")\n",
        "            print(\"Choose difficulty level:\")\n",
        "            print(\"1. Easy\")\n",
        "            print(\"2. Medium\")\n",
        "            print(\"3. Hard\")\n",
        "            difficulty_choice = input(\"Enter difficulty level (1/2/3): \").strip()\n",
        "            level = difficulty_map.get(difficulty_choice, \"Easy\")  # Default to Easy if invalid input\n",
        "            print(\"\\nGenerating quiz...\\n\")\n",
        "            quiz = generate_quiz(subject, level)\n",
        "            print(quiz)\n",
        "\n",
        "        elif user_input == \"2\":  # Create Summary\n",
        "            subject = input(\"Enter the subject: \")\n",
        "            topic = input(\"Enter the topic: \")\n",
        "            print(\"\\nGenerating summary...\\n\")\n",
        "            summary = generate_summary(subject, topic)\n",
        "            print(summary)\n",
        "\n",
        "        elif user_input == \"3\":  # Create E-Learning Materials\n",
        "            subject = input(\"Enter the subject: \")\n",
        "            topic = input(\"Enter the topic: \")\n",
        "            print(\"\\nGenerating e-learning material...\\n\")\n",
        "            material = generate_material(subject, topic)\n",
        "            print(material)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# Run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "metadata": {
        "id": "LZhMSo48p19R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Langchain x Gemini, upload txt file path in code to get quiz from it\n",
        "# Install required libraries\n",
        "!pip install -q langchain langchain-google-genai google-generativeai\n",
        "\n",
        "# Import necessary modules\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Set your Google API key\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyC2_dKggLQ_4cdDqb8W047P6PzP0rcsUbI'\n",
        "\n",
        "# Initialize the Gemini model using LangChain\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "\n",
        "# Define prompt template for generating quizzes\n",
        "quiz_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"level\", \"input_text\"],\n",
        "    template=\"You are a helpful AI tutor. Generate 10 {level} level quiz questions based on the following text: \\n\\n{input_text}\\n\\nSubject: {subject}.\"\n",
        ")\n",
        "\n",
        "# Create LLMChain for quiz generation\n",
        "quiz_chain = LLMChain(llm=llm, prompt=quiz_prompt)\n",
        "\n",
        "# Load the text file\n",
        "file_path = \"/content/Artificial Intelligence.txt\"  # Replace with the path to your .txt file\n",
        "loader = TextLoader(file_path)\n",
        "documents = loader.load()\n",
        "\n",
        "# Split the document into smaller chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# Function to generate quiz from text\n",
        "def generate_quiz_from_text(subject, level=\"Medium\", text_chunk=None):\n",
        "    if not text_chunk:\n",
        "        print(\"No text provided for quiz generation.\")\n",
        "        return None\n",
        "    return quiz_chain.run(subject=subject, level=level, input_text=text_chunk)\n",
        "\n",
        "# Interactive chatbot loop\n",
        "def chatbot():\n",
        "    print(\"Welcome to the E-Learning Content Generator!\")\n",
        "    print(\"You can ask me to generate quizzes from a text file.\")\n",
        "    print(\"Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nWhat would you like me to do? (e.g., 'Generate quiz from text'): \").strip().lower()\n",
        "\n",
        "        if user_input == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        elif \"quiz\" in user_input:\n",
        "            subject = input(\"Enter the subject: \")\n",
        "            print(\"Choose difficulty level:\")\n",
        "            print(\"1. Easy\")\n",
        "            print(\"2. Medium\")\n",
        "            print(\"3. Hard\")\n",
        "            difficulty_choice = input(\"Enter difficulty level (1/2/3): \").strip()\n",
        "            level_map = {\"1\": \"Easy\", \"2\": \"Medium\", \"3\": \"Hard\"}\n",
        "            level = level_map.get(difficulty_choice, \"Medium\")  # Default to Medium if invalid input\n",
        "\n",
        "            # Use the first chunk of text for quiz generation\n",
        "            if texts:\n",
        "                text_chunk = texts[0].page_content  # Use the first chunk of text\n",
        "                print(\"\\nGenerating quiz...\\n\")\n",
        "                quiz = generate_quiz_from_text(subject=subject, level=level, text_chunk=text_chunk)\n",
        "                print(quiz)\n",
        "            else:\n",
        "                print(\"No text chunks available for quiz generation.\")\n",
        "\n",
        "        else:\n",
        "            print(\"I'm sorry, I didn't understand that. Please try again.\")\n",
        "\n",
        "# Run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "metadata": {
        "id": "F0vktNpsncPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Langchain x Gemini, upload a text file from your system to get quiz from it\n",
        "# Install required libraries\n",
        "!pip install -q langchain langchain-google-genai google-generativeai ipywidgets\n",
        "\n",
        "# Import necessary modules\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Set your Google API key\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyC2_dKggLQ_4cdDqb8W047P6PzP0rcsUbI'\n",
        "\n",
        "# Initialize the Gemini model using LangChain\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "\n",
        "# Define prompt template for generating quizzes\n",
        "quiz_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"level\", \"input_text\"],\n",
        "    template=\"You are a helpful AI tutor. Generate 10 {level} level quiz questions based on the following text: \\n\\n{input_text}\\n\\nSubject: {subject}.\"\n",
        ")\n",
        "\n",
        "# Create LLMChain for quiz generation\n",
        "quiz_chain = LLMChain(llm=llm, prompt=quiz_prompt)\n",
        "\n",
        "# Function to load and split the uploaded document\n",
        "def load_and_split_document(file_path):\n",
        "    loader = TextLoader(file_path)\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    return texts\n",
        "\n",
        "# Function to generate quiz from text\n",
        "def generate_quiz_from_text(subject, level=\"Medium\", text_chunk=None):\n",
        "    if not text_chunk:\n",
        "        print(\"No text provided for quiz generation.\")\n",
        "        return None\n",
        "    return quiz_chain.run(subject=subject, level=level, input_text=text_chunk)\n",
        "\n",
        "# Interactive chatbot loop\n",
        "def chatbot():\n",
        "    print(\"Welcome to the E-Learning Content Generator!\")\n",
        "    print(\"Upload a document and I'll generate quizzes from it.\")\n",
        "\n",
        "    # File upload widget\n",
        "    file_upload = widgets.FileUpload(\n",
        "        accept='.txt',  # Accept only .txt files\n",
        "        multiple=False  # Only allow one file to be uploaded\n",
        "    )\n",
        "    display(file_upload)\n",
        "\n",
        "    # Subject input widget\n",
        "    subject_input = widgets.Text(\n",
        "        placeholder=\"Enter the subject\",\n",
        "        description=\"Subject:\",\n",
        "        disabled=False\n",
        "    )\n",
        "\n",
        "    # Difficulty level dropdown\n",
        "    difficulty_dropdown = widgets.Dropdown(\n",
        "        options=[(\"Easy\", \"Easy\"), (\"Medium\", \"Medium\"), (\"Hard\", \"Hard\")],\n",
        "        value=\"Medium\",\n",
        "        description=\"Difficulty:\",\n",
        "        disabled=False\n",
        "    )\n",
        "\n",
        "    # Generate quiz button\n",
        "    generate_button = widgets.Button(\n",
        "        description=\"Generate Quiz\",\n",
        "        disabled=True,\n",
        "        button_style=\"success\"\n",
        "    )\n",
        "\n",
        "    # Output area for displaying the quiz\n",
        "    output_area = widgets.Output()\n",
        "\n",
        "    # Display widgets\n",
        "    display(widgets.VBox([subject_input, difficulty_dropdown, generate_button]))\n",
        "\n",
        "    # Track whether a file has been uploaded\n",
        "    file_uploaded = False\n",
        "    texts = None\n",
        "\n",
        "    def on_file_upload_change(change):\n",
        "        nonlocal file_uploaded, texts\n",
        "        if change['new']:  # Check if a file has been uploaded\n",
        "            uploaded_file = next(iter(file_upload.value.values()))  # Get the uploaded file\n",
        "            file_content = uploaded_file['content'].decode('utf-8')  # Decode file content\n",
        "\n",
        "            # Save the uploaded file locally\n",
        "            file_path = \"/tmp/uploaded_file.txt\"\n",
        "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(file_content)\n",
        "\n",
        "            # Load and split the document\n",
        "            texts = load_and_split_document(file_path)\n",
        "            file_uploaded = True\n",
        "            generate_button.disabled = False  # Enable the generate button\n",
        "            print(\"File uploaded successfully!\")\n",
        "\n",
        "    # Attach the event listener to the file upload widget\n",
        "    file_upload.observe(on_file_upload_change, names='value')\n",
        "\n",
        "    # Handle quiz generation when the button is clicked\n",
        "    def on_generate_button_click(b):\n",
        "        if not file_uploaded or not texts:\n",
        "            with output_area:\n",
        "                print(\"Please upload a file first.\")\n",
        "            return\n",
        "\n",
        "        subject = subject_input.value.strip()\n",
        "        level = difficulty_dropdown.value\n",
        "\n",
        "        if not subject:\n",
        "            with output_area:\n",
        "                print(\"Please enter a subject.\")\n",
        "            return\n",
        "\n",
        "        # Use the first chunk of text for quiz generation\n",
        "        text_chunk = texts[0].page_content  # Use the first chunk of text\n",
        "\n",
        "        with output_area:\n",
        "            print(\"\\nGenerating quiz...\\n\")\n",
        "            quiz = generate_quiz_from_text(subject=subject, level=level, text_chunk=text_chunk)\n",
        "            print(quiz)\n",
        "\n",
        "    # Attach the button click event\n",
        "    generate_button.on_click(on_generate_button_click)\n",
        "\n",
        "    # Display the output area\n",
        "    display(output_area)\n",
        "\n",
        "# Run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "metadata": {
        "id": "8rIn_8Z1pEj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Langchain x Gemini, can upload a .txt, .pdf, .docx file from your system to get quiz from it\n",
        "# Install required libraries\n",
        "!pip install -q langchain langchain-google-genai google-generativeai ipywidgets\n",
        "\n",
        "# Import necessary modules\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader, UnstructuredWordDocumentLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Set your Google API key\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyC2_dKggLQ_4cdDqb8W047P6PzP0rcsUbI'\n",
        "\n",
        "# Initialize the Gemini model using LangChain\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "\n",
        "# Define prompt template for generating quizzes\n",
        "quiz_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"level\", \"input_text\"],\n",
        "    template=\"You are a helpful AI tutor. Generate 10 {level} level quiz questions based on the following text: \\n\\n{input_text}\\n\\nSubject: {subject}.\"\n",
        ")\n",
        "\n",
        "# Create LLMChain for quiz generation\n",
        "quiz_chain = LLMChain(llm=llm, prompt=quiz_prompt)\n",
        "\n",
        "# Function to load and split the uploaded document\n",
        "def load_and_split_document(file_path, file_extension):\n",
        "    if file_extension == \".txt\":\n",
        "        loader = TextLoader(file_path)\n",
        "    elif file_extension == \".pdf\":\n",
        "        loader = PyPDFLoader(file_path)\n",
        "    elif file_extension == \".docx\":\n",
        "        loader = UnstructuredWordDocumentLoader(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please upload a .txt, .pdf, or .docx file.\")\n",
        "\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    return texts\n",
        "\n",
        "# Function to generate quiz from text\n",
        "def generate_quiz_from_text(subject, level=\"Medium\", text_chunk=None):\n",
        "    if not text_chunk:\n",
        "        print(\"No text provided for quiz generation.\")\n",
        "        return None\n",
        "    return quiz_chain.run(subject=subject, level=level, input_text=text_chunk)\n",
        "\n",
        "# Interactive chatbot loop\n",
        "def chatbot():\n",
        "    print(\"Welcome to the E-Learning Content Generator!\")\n",
        "    print(\"Upload a document (.txt, .pdf, .docx) and I'll generate quizzes from it.\")\n",
        "\n",
        "    # File upload widget\n",
        "    file_upload = widgets.FileUpload(\n",
        "        accept='.txt,.pdf,.docx',  # Accept .txt, .pdf, and .docx files\n",
        "        multiple=False  # Only allow one file to be uploaded\n",
        "    )\n",
        "    display(file_upload)\n",
        "\n",
        "    # Subject input widget\n",
        "    subject_input = widgets.Text(\n",
        "        placeholder=\"Enter the subject\",\n",
        "        description=\"Subject:\",\n",
        "        disabled=False\n",
        "    )\n",
        "\n",
        "    # Difficulty level dropdown\n",
        "    difficulty_dropdown = widgets.Dropdown(\n",
        "        options=[(\"Easy\", \"Easy\"), (\"Medium\", \"Medium\"), (\"Hard\", \"Hard\")],\n",
        "        value=\"Medium\",\n",
        "        description=\"Difficulty:\",\n",
        "        disabled=False\n",
        "    )\n",
        "\n",
        "    # Generate quiz button\n",
        "    generate_button = widgets.Button(\n",
        "        description=\"Generate Quiz\",\n",
        "        disabled=True,\n",
        "        button_style=\"success\"\n",
        "    )\n",
        "\n",
        "    # Output area for displaying the quiz\n",
        "    output_area = widgets.Output()\n",
        "\n",
        "    # Display widgets\n",
        "    display(widgets.VBox([subject_input, difficulty_dropdown, generate_button]))\n",
        "\n",
        "    # Track whether a file has been uploaded\n",
        "    file_uploaded = False\n",
        "    texts = None\n",
        "\n",
        "    def on_file_upload_change(change):\n",
        "        nonlocal file_uploaded, texts\n",
        "        if change['new']:  # Check if a file has been uploaded\n",
        "            uploaded_file = next(iter(file_upload.value.values()))  # Get the uploaded file\n",
        "            file_content = uploaded_file['content']\n",
        "\n",
        "            # Determine the file extension\n",
        "            file_name = uploaded_file['name']\n",
        "            _, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "            # Save the uploaded file locally\n",
        "            file_path = f\"/tmp/uploaded_file{file_extension}\"\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                f.write(file_content)\n",
        "\n",
        "            try:\n",
        "                # Load and split the document\n",
        "                texts = load_and_split_document(file_path, file_extension)\n",
        "                file_uploaded = True\n",
        "                generate_button.disabled = False  # Enable the generate button\n",
        "                print(f\"{file_extension.upper()} file uploaded successfully!\")\n",
        "            except ValueError as e:\n",
        "                with output_area:\n",
        "                    print(e)\n",
        "\n",
        "    # Attach the event listener to the file upload widget\n",
        "    file_upload.observe(on_file_upload_change, names='value')\n",
        "\n",
        "    # Handle quiz generation when the button is clicked\n",
        "    def on_generate_button_click(b):\n",
        "        if not file_uploaded or not texts:\n",
        "            with output_area:\n",
        "                print(\"Please upload a file first.\")\n",
        "            return\n",
        "\n",
        "        subject = subject_input.value.strip()\n",
        "        level = difficulty_dropdown.value\n",
        "\n",
        "        if not subject:\n",
        "            with output_area:\n",
        "                print(\"Please enter a subject.\")\n",
        "            return\n",
        "\n",
        "        # Use the first chunk of text for quiz generation\n",
        "        text_chunk = texts[0].page_content  # Use the first chunk of text\n",
        "\n",
        "        with output_area:\n",
        "            print(\"\\nGenerating quiz...\\n\")\n",
        "            quiz = generate_quiz_from_text(subject=subject, level=level, text_chunk=text_chunk)\n",
        "            print(quiz)\n",
        "\n",
        "    # Attach the button click event\n",
        "    generate_button.on_click(on_generate_button_click)\n",
        "\n",
        "    # Display the output area\n",
        "    display(output_area)\n",
        "\n",
        "# Run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "metadata": {
        "id": "M5ZD1Jdbr4zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -q langchain langchain-google-genai google-generativeai ipywidgets\n",
        "\n",
        "# Import necessary modules\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader, UnstructuredWordDocumentLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Set your Google API key\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyC2_dKggLQ_4cdDqb8W047P6PzP0rcsUbI'\n",
        "\n",
        "# Initialize the Gemini model using LangChain\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "\n",
        "# Define prompt templates for different tasks\n",
        "quiz_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"level\"],\n",
        "    template=\"You are a helpful AI tutor. Generate 10 {level} level quiz questions for {subject}.\"\n",
        ")\n",
        "\n",
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"topic\"],\n",
        "    template=\"You are an expert in {subject}. Provide a concise summary of the topic: {topic}.\"\n",
        ")\n",
        "\n",
        "material_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"topic\"],\n",
        "    template=\"You are an expert in {subject}. Generate detailed e-learning material on the topic: {topic}.\"\n",
        ")\n",
        "\n",
        "quiz_from_text_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"level\", \"input_text\"],\n",
        "    template=\"You are a helpful AI tutor. Generate 10 {level} level quiz questions based on the following text: \\n\\n{input_text}\\n\\nSubject: {subject}.\"\n",
        ")\n",
        "\n",
        "# Create LLMChains for each task\n",
        "quiz_chain = LLMChain(llm=llm, prompt=quiz_prompt)\n",
        "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
        "material_chain = LLMChain(llm=llm, prompt=material_prompt)\n",
        "quiz_from_text_chain = LLMChain(llm=llm, prompt=quiz_from_text_prompt)\n",
        "\n",
        "# Function to load and split the uploaded document\n",
        "def load_and_split_document(file_path, file_extension):\n",
        "    if file_extension == \".txt\":\n",
        "        loader = TextLoader(file_path)\n",
        "    elif file_extension == \".pdf\":\n",
        "        loader = PyPDFLoader(file_path)\n",
        "    elif file_extension == \".docx\":\n",
        "        loader = UnstructuredWordDocumentLoader(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please upload a .txt, .pdf, or .docx file.\")\n",
        "\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    return texts\n",
        "\n",
        "# Function to generate quiz questions\n",
        "def generate_quiz(subject, level=\"Easy\"):\n",
        "    return quiz_chain.run(subject=subject, level=level)\n",
        "\n",
        "# Function to generate summaries\n",
        "def generate_summary(subject, topic):\n",
        "    return summary_chain.run(subject=subject, topic=topic)\n",
        "\n",
        "# Function to generate e-learning materials\n",
        "def generate_material(subject, topic):\n",
        "    return material_chain.run(subject=subject, topic=topic)\n",
        "\n",
        "# Function to generate quiz from text\n",
        "def generate_quiz_from_text(subject, level=\"Medium\", text_chunk=None):\n",
        "    if not text_chunk:\n",
        "        print(\"No text provided for quiz generation.\")\n",
        "        return None\n",
        "    return quiz_from_text_chain.run(subject=subject, level=level, input_text=text_chunk)\n",
        "\n",
        "# Map numeric inputs to difficulty levels\n",
        "difficulty_map = {\n",
        "    \"1\": \"Easy\",\n",
        "    \"2\": \"Medium\",\n",
        "    \"3\": \"Hard\"\n",
        "}\n",
        "\n",
        "# Interactive chatbot loop\n",
        "def chatbot():\n",
        "    print(\"Welcome to the E-Learning Content Generator!\")\n",
        "    print(\"Choose an option:\")\n",
        "    print(\"1. Generate Quiz\")\n",
        "    print(\"2. Create Summary\")\n",
        "    print(\"3. Create E-Learning Materials\")\n",
        "    print(\"Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nEnter your choice (1/2/3): \").strip().lower()\n",
        "\n",
        "        if user_input == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        elif user_input == \"1\":  # Generate Quiz\n",
        "            print(\"Would you like to:\")\n",
        "            print(\"A. Upload a document (.txt, .pdf, .docx) and generate quiz questions from it?\")\n",
        "            print(\"B. Generate quiz questions directly?\")\n",
        "            quiz_choice = input(\"Enter your choice (A/B): \").strip().upper()\n",
        "\n",
        "            if quiz_choice == \"A\":  # Upload a document\n",
        "                # File upload widget\n",
        "                file_upload = widgets.FileUpload(\n",
        "                    accept='.txt,.pdf,.docx',  # Accept .txt, .pdf, and .docx files\n",
        "                    multiple=False  # Only allow one file to be uploaded\n",
        "                )\n",
        "                display(file_upload)\n",
        "\n",
        "                # Subject input widget\n",
        "                subject_input = widgets.Text(\n",
        "                    placeholder=\"Enter the subject\",\n",
        "                    description=\"Subject:\",\n",
        "                    disabled=False\n",
        "                )\n",
        "\n",
        "                # Difficulty level dropdown\n",
        "                difficulty_dropdown = widgets.Dropdown(\n",
        "                    options=[(\"Easy\", \"Easy\"), (\"Medium\", \"Medium\"), (\"Hard\", \"Hard\")],\n",
        "                    value=\"Medium\",\n",
        "                    description=\"Difficulty:\",\n",
        "                    disabled=False\n",
        "                )\n",
        "\n",
        "                # Generate quiz button\n",
        "                generate_button = widgets.Button(\n",
        "                    description=\"Generate Quiz\",\n",
        "                    disabled=True,\n",
        "                    button_style=\"success\"\n",
        "                )\n",
        "\n",
        "                # Output area for displaying the quiz\n",
        "                output_area = widgets.Output()\n",
        "\n",
        "                # Display widgets\n",
        "                display(widgets.VBox([subject_input, difficulty_dropdown, generate_button]))\n",
        "\n",
        "                # Track whether a file has been uploaded\n",
        "                file_uploaded = False\n",
        "                texts = None\n",
        "\n",
        "                def on_file_upload_change(change):\n",
        "                    nonlocal file_uploaded, texts\n",
        "                    if change['new']:  # Check if a file has been uploaded\n",
        "                        uploaded_file = next(iter(file_upload.value.values()))  # Get the uploaded file\n",
        "                        file_content = uploaded_file['content']\n",
        "\n",
        "                        # Determine the file extension\n",
        "                        file_name = uploaded_file['name']\n",
        "                        _, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "                        # Save the uploaded file locally\n",
        "                        file_path = f\"/tmp/uploaded_file{file_extension}\"\n",
        "                        with open(file_path, \"wb\") as f:\n",
        "                            f.write(file_content)\n",
        "\n",
        "                        try:\n",
        "                            # Load and split the document\n",
        "                            texts = load_and_split_document(file_path, file_extension)\n",
        "                            file_uploaded = True\n",
        "                            generate_button.disabled = False  # Enable the generate button\n",
        "                            print(f\"{file_extension.upper()} file uploaded successfully!\")\n",
        "                        except ValueError as e:\n",
        "                            with output_area:\n",
        "                                print(e)\n",
        "\n",
        "                # Attach the event listener to the file upload widget\n",
        "                file_upload.observe(on_file_upload_change, names='value')\n",
        "\n",
        "                # Handle quiz generation when the button is clicked\n",
        "                def on_generate_button_click(b):\n",
        "                    if not file_uploaded or not texts:\n",
        "                        with output_area:\n",
        "                            print(\"Please upload a file first.\")\n",
        "                        return\n",
        "\n",
        "                    subject = subject_input.value.strip()\n",
        "                    level = difficulty_dropdown.value\n",
        "\n",
        "                    if not subject:\n",
        "                        with output_area:\n",
        "                            print(\"Please enter a subject.\")\n",
        "                        return\n",
        "\n",
        "                    # Use the first chunk of text for quiz generation\n",
        "                    text_chunk = texts[0].page_content\n",
        "                    with output_area:\n",
        "                        print(\"\\nGenerating quiz...\\n\")\n",
        "                        quiz = generate_quiz_from_text(subject=subject, level=level, text_chunk=text_chunk)\n",
        "                        print(quiz)\n",
        "\n",
        "                # Attach the button click event\n",
        "                generate_button.on_click(on_generate_button_click)\n",
        "\n",
        "                # Display the output area\n",
        "                display(output_area)\n",
        "\n",
        "            elif quiz_choice == \"B\":  # Generate quiz directly\n",
        "                subject = input(\"Enter the subject: \")\n",
        "                print(\"Choose difficulty level:\")\n",
        "                print(\"1. Easy\")\n",
        "                print(\"2. Medium\")\n",
        "                print(\"3. Hard\")\n",
        "                difficulty_choice = input(\"Enter difficulty level (1/2/3): \").strip()\n",
        "                level = difficulty_map.get(difficulty_choice, \"Easy\")  # Default to Easy if invalid input\n",
        "                print(\"\\nGenerating quiz...\\n\")\n",
        "                quiz = generate_quiz(subject, level)\n",
        "                print(quiz)\n",
        "\n",
        "            else:\n",
        "                print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "        elif user_input == \"2\":  # Create Summary\n",
        "            subject = input(\"Enter the subject: \")\n",
        "            topic = input(\"Enter the topic: \")\n",
        "            print(\"\\nGenerating summary...\\n\")\n",
        "            summary = generate_summary(subject, topic)\n",
        "            print(summary)\n",
        "\n",
        "        elif user_input == \"3\":  # Create E-Learning Materials\n",
        "            subject = input(\"Enter the subject: \")\n",
        "            topic = input(\"Enter the topic: \")\n",
        "            print(\"\\nGenerating e-learning material...\\n\")\n",
        "            material = generate_material(subject, topic)\n",
        "            print(material)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "# Run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2a4cc9368c8845699f2c280b84379be0",
            "e92de49b9c794204bcf7fec13acc9d92",
            "eaf0a6e745a94a9fa42171951a281b6c",
            "d2d1040d779d46cc94e32d2f52017a9a",
            "a37dce884a6742e380c571a3f4908e8c",
            "6c84533b7c9d4886a70880b08b3d17f0",
            "bd5e18de42d6455cb2790ea1714fa8ea",
            "5b529f4c24864e409a6a4d9328fe7744",
            "73e5d2eaa9da44eeaa61a3fcf293467d",
            "42e6ebb804ea4c1f8d4063efaa888c03",
            "f785f746eed14f60b559fb62d1663313",
            "d5a54ddba45a4b24a63ea81f1de0de88",
            "3a1e79e1c86b4a99b0086ada058fb663",
            "7fd13c01e792450f8baa14c6e03b67aa",
            "871674c53f6c453d9dd2b2459ad5ee71",
            "bac96d18182e415688f297d2fee833d2"
          ]
        },
        "id": "oXdvvlEhvog8",
        "outputId": "bfcc0692-5fc0-4603-d81f-8e3646bffffa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the E-Learning Content Generator!\n",
            "Choose an option:\n",
            "1. Generate Quiz\n",
            "2. Create Summary\n",
            "3. Create E-Learning Materials\n",
            "Type 'exit' to quit.\n",
            "\n",
            "Enter your choice (1/2/3): 1\n",
            "Would you like to:\n",
            "A. Upload a document (.txt, .pdf, .docx) and generate quiz questions from it?\n",
            "B. Generate quiz questions directly?\n",
            "Enter your choice (A/B): A\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='.txt,.pdf,.docx', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a4cc9368c8845699f2c280b84379be0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Text(value='', description='Subject:', placeholder='Enter the subject'), Dropdown(description='…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2d1040d779d46cc94e32d2f52017a9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "871674c53f6c453d9dd2b2459ad5ee71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter your choice (1/2/3): 2\n",
            "Enter the subject: Math\n",
            "Enter the topic: Calculas\n",
            "\n",
            "Generating summary...\n",
            "\n",
            "**Calculus**\n",
            "\n",
            "Calculus is a branch of mathematics that deals with the study of change. It provides a framework for understanding and analyzing functions, their derivatives, integrals, and limits.\n",
            "\n",
            "**Key Concepts:**\n",
            "\n",
            "* **Derivatives:** Measure the instantaneous rate of change of a function.\n",
            "* **Integrals:** Accumulate or sum the area under a curve or the volume of a solid.\n",
            "* **Limits:** Determine the behavior of a function as its input approaches a certain value.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "Calculus has wide-ranging applications in:\n",
            "\n",
            "* Physics (e.g., motion, gravity)\n",
            "* Engineering (e.g., design, optimization)\n",
            "* Economics (e.g., growth, optimization)\n",
            "* Biology (e.g., population dynamics, growth models)\n",
            "* Computer science (e.g., algorithms, numerical analysis)\n",
            "\n",
            "**Types of Calculus:**\n",
            "\n",
            "* **Differential calculus:** Focuses on derivatives and their applications.\n",
            "* **Integral calculus:** Focuses on integrals and their applications.\n",
            "* **Multivariable calculus:** Extends calculus to functions of multiple variables.\n",
            "\n",
            "**Fundamental Theorems:**\n",
            "\n",
            "* **Fundamental Theorem of Calculus:** Connects derivatives and integrals.\n",
            "* **Mean Value Theorem:** States that a function's average rate of change is equal to its instantaneous rate of change at some point in its domain.\n",
            "\n",
            "**Significance:**\n",
            "\n",
            "Calculus is a powerful tool that enables scientists, engineers, and mathematicians to model, analyze, and solve complex problems involving change and optimization.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-68ecb085d3bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;31m# Run the chatbot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-68ecb085d3bb>\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEnter your choice (1/2/3): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36m_handle_msg\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    754\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'buffer_paths'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0m_put_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'buffer_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'buffers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;31m# Handle a state request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36mset_state\u001b[0;34m(self, sync_data)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# be locked when the hold_trait_notification context manager is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;31m# released and notifications are fired.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msync_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold_trait_notifications\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msync_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mhold_trait_notifications\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchanges\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchanges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[0;31m# Send new state to front-end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWidget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m   1511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0;34m\"\"\"Notify observers of a change event\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_notify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m_notify_observers\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m   1558\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_notifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipywidgets/widgets/widget_upload.py\u001b[0m in \u001b[0;36mon_incr_counter\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'content'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mset_trait\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTraitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Class {cls.__name__} does not have a trait named {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1738\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;31m# we explicitly compare silent to True just in case the equality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;31m# comparison above returns something other than True/False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m_notify_trait\u001b[0;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m         self.notify_change(\n\u001b[0m\u001b[1;32m   1502\u001b[0m             Bunch(\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[0;31m# Send new state to front-end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWidget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m   1511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0;34m\"\"\"Notify observers of a change event\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_notify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m_notify_observers\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m   1558\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_notifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-68ecb085d3bb>\u001b[0m in \u001b[0;36mon_file_upload_change\u001b[0;34m(change)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                         \u001b[0;31m# Determine the file extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                         \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muploaded_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_extension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -q langchain langchain-google-genai google-generativeai ipywidgets langchain-community\n",
        "\n",
        "# Import necessary modules\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader, Docx2txtLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Set your Google API key (Ensure you have set up Google Generative AI API access)\n",
        "os.environ['GOOGLE_API_KEY'] = 'YOUR_GOOGLE_API_KEY_HERE'\n",
        "\n",
        "# Initialize the Gemini model using LangChain\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "\n",
        "# Define prompt template for generating quizzes\n",
        "quiz_prompt = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"level\", \"input_text\"],\n",
        "    template=\"You are a helpful AI tutor. Generate 10 {level} level quiz questions based on the following text: \\n\\n{input_text}\\n\\nSubject: {subject}.\"\n",
        ")\n",
        "\n",
        "# Create LLMChain for quiz generation\n",
        "quiz_chain = LLMChain(llm=llm, prompt=quiz_prompt)\n",
        "\n",
        "# Function to load and split the uploaded document\n",
        "def load_and_split_document(file_path, file_extension):\n",
        "    if file_extension == \".txt\":\n",
        "        loader = TextLoader(file_path)\n",
        "    elif file_extension == \".pdf\":\n",
        "        loader = PyPDFLoader(file_path)\n",
        "    elif file_extension == \".docx\":\n",
        "        loader = Docx2txtLoader(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please upload a .txt, .pdf, or .docx file.\")\n",
        "\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    return texts\n",
        "\n",
        "# Function to generate quiz from text\n",
        "def generate_quiz_from_text(subject, level=\"Medium\", text_chunk=None):\n",
        "    if not text_chunk:\n",
        "        print(\"No text provided for quiz generation.\")\n",
        "        return None\n",
        "    return quiz_chain.run(subject=subject, level=level, input_text=text_chunk)\n",
        "\n",
        "# Interactive chatbot loop\n",
        "def chatbot():\n",
        "    print(\"Welcome to the E-Learning Content Generator!\")\n",
        "    print(\"Upload a document (.txt, .pdf, .docx) and I'll generate quizzes from it.\")\n",
        "\n",
        "    # File upload widget\n",
        "    file_upload = widgets.FileUpload(\n",
        "        accept='.txt,.pdf,.docx',  # Accept .txt, .pdf, and .docx files\n",
        "        multiple=False  # Only allow one file to be uploaded\n",
        "    )\n",
        "    display(file_upload)\n",
        "\n",
        "    # Subject input widget\n",
        "    subject_input = widgets.Text(\n",
        "        placeholder=\"Enter the subject\",\n",
        "        description=\"Subject:\",\n",
        "        disabled=False\n",
        "    )\n",
        "\n",
        "    # Difficulty level dropdown\n",
        "    difficulty_dropdown = widgets.Dropdown(\n",
        "        options=[(\"Easy\", \"Easy\"), (\"Medium\", \"Medium\"), (\"Hard\", \"Hard\")],\n",
        "        value=\"Medium\",\n",
        "        description=\"Difficulty:\",\n",
        "        disabled=False\n",
        "    )\n",
        "\n",
        "    # Generate quiz button\n",
        "    generate_button = widgets.Button(\n",
        "        description=\"Generate Quiz\",\n",
        "        disabled=True,\n",
        "        button_style=\"success\"\n",
        "    )\n",
        "\n",
        "    # Output area for displaying the quiz\n",
        "    output_area = widgets.Output()\n",
        "\n",
        "    # Display widgets\n",
        "    display(widgets.VBox([subject_input, difficulty_dropdown, generate_button]))\n",
        "\n",
        "    # Track whether a file has been uploaded\n",
        "    file_uploaded = False\n",
        "    texts = None\n",
        "\n",
        "    def on_file_upload_change(change):\n",
        "        nonlocal file_uploaded, texts\n",
        "        if change['new']:  # Check if a file has been uploaded\n",
        "            uploaded_file = next(iter(file_upload.value.values()))  # Get the uploaded file\n",
        "            file_content = uploaded_file['content']\n",
        "\n",
        "            # Determine the file extension\n",
        "            file_name = uploaded_file['name']\n",
        "            _, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "            # Save the uploaded file locally\n",
        "            file_path = f\"/tmp/uploaded_file{file_extension}\"\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                f.write(file_content)\n",
        "\n",
        "            try:\n",
        "                # Load and split the document\n",
        "                texts = load_and_split_document(file_path, file_extension)\n",
        "                file_uploaded = True\n",
        "                generate_button.disabled = False  # Enable the generate button\n",
        "                with output_area:\n",
        "                    print(f\"{file_extension.upper()} file uploaded successfully!\")\n",
        "            except ValueError as e:\n",
        "                with output_area:\n",
        "                    print(e)\n",
        "\n",
        "    # Attach the event listener to the file upload widget\n",
        "    file_upload.observe(on_file_upload_change, names='value')\n",
        "\n",
        "    # Handle quiz generation when the button is clicked\n",
        "    def on_generate_button_click(b):\n",
        "        if not file_uploaded or not texts:\n",
        "            with output_area:\n",
        "                print(\"Please upload a file first.\")\n",
        "            return\n",
        "\n",
        "        subject = subject_input.value.strip()\n",
        "        level = difficulty_dropdown.value\n",
        "\n",
        "        if not subject:\n",
        "            with output_area:\n",
        "                print(\"Please enter a subject.\")\n",
        "            return\n",
        "\n",
        "        # Use the first chunk of text for quiz generation\n",
        "        text_chunk = texts[0]  # Extract first chunk\n",
        "\n",
        "        with output_area:\n",
        "            print(\"\\nGenerating quiz...\\n\")\n",
        "            quiz = generate_quiz_from_text(subject=subject, level=level, text_chunk=text_chunk)\n",
        "            print(quiz)\n",
        "\n",
        "    # Attach the button click event\n",
        "    generate_button.on_click(on_generate_button_click)\n",
        "\n",
        "    # Display the output area\n",
        "    display(output_area)\n",
        "\n",
        "# Run the chatbot\n",
        "chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180,
          "referenced_widgets": [
            "2ff2e320dfe24887a048dcad2dcee5b1",
            "617514676ec0468b8621712fc92a5151",
            "867e50b9906747ee85fd6b31c04d2de2",
            "fa65b84d871d49a0a0fb5a1207fe3509",
            "aadbb983a395473c9ba9c653e24b7b4a",
            "7f209fd41b4b46beac932f4d981ab377",
            "7bb3703264e241a681b3096eb08159c8",
            "2579f9c8dcaa4f8f8cab9bd34695f773",
            "9ad77a86347e435eb54c9645353c2eb1",
            "904ff46d2f4944c69ea14f78d6249661",
            "75029c3e235a42e0924aafc41f6de07c",
            "3f555564611443f2b1c3bf63754e7460",
            "cd41f89c82e743bc909796427bda0e2c",
            "b7acceb23c0c4bf4878731fc994181c4",
            "d5f2ffa9f88143d2900d67bc09d668f7",
            "27c6d1f959ca4688a6c20323f9e2e42d"
          ]
        },
        "id": "UXOEssTO2mCU",
        "outputId": "d27af93c-4f6f-4230-e340-6b62669cd6cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the E-Learning Content Generator!\n",
            "Upload a document (.txt, .pdf, .docx) and I'll generate quizzes from it.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='.txt,.pdf,.docx', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ff2e320dfe24887a048dcad2dcee5b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Text(value='', description='Subject:', placeholder='Enter the subject'), Dropdown(description='…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa65b84d871d49a0a0fb5a1207fe3509"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5f2ffa9f88143d2900d67bc09d668f7"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}